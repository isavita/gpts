# Generate Advent Of Code solutions with LLM

```elixir
Mix.install([
  :req,
  :json,
  :bumblebee,
  :wise_gpt_ex
])

Application.put_env(:wise_gpt_ex, :openai_api_key, System.fetch_env!("LB_OPENAI_API_KEY"))
Application.put_env(:wise_gpt_ex, :mistral_api_key, System.fetch_env!("LB_MISTRAL_API_KEY"))
```

## Load all advent of code from hugging face

```elixir
dataset_url = "https://huggingface.co/datasets/isavita/advent-of-code/raw/main/train.json"
dataset = Req.get!(dataset_url).body |> Jason.decode!()
```

```elixir
dataset_2016 = Enum.filter(dataset, &(&1["year"] == 2016 && &1["solution_lang"] == "go"))
```

## Manage Request to Mistral API

```elixir
defmodule MistralClient do
  # 5 mins
  @timeout 300_000
  @url "https://api.mistral.ai/v1/chat/completions"
  @system_prompt """
  You are an expert programmer that writes simple, concise code and no comments or explanation.
  Write a elixir module that it reads its input from a file "input.txt" and solve the following task.
  The module should have only one public function called `call` with arity 0.
  TASK:
  """
  def call(model, task) do
    prompt = "#{@system_prompt}#{task}"

    payload =
      %{
        "model" => model,
        "messages" => [
          %{"role" => "user", "content" => prompt}
        ],
        "temperature" => 0.1,
        "stream" => false
      }
      |> Jason.encode!()

    Req.post!(@url, body: payload, headers: headers(), receive_timeout: @timeout).body
    |> Map.get("choices", [%{}])
    |> hd()
    |> get_in(["message", "content"])
  end

  defp headers do
    [
      {"Content-Type", "application/json"},
      {"Accept", "application/json"},
      {"Authorization", "Bearer " <> mistral_api_key()}
    ]
  end

  defp mistral_api_key, do: System.fetch_env!("LB_MISTRAL_API_KEY")
end
```

```elixir
defmodule OpenAIClient do
  # 5 mins
  @timeout 300_000
  @url "https://api.openai.com/v1/chat/completions"
  @system_prompt """
  You are an expert programmer that writes simple, concise code and no comments or explanation.
  Write a elixir module that it reads its input from a file "input.txt" and solve the following task.
  The module should have only one public function called `call` with arity 0.
  TASK:
  """
  def call(model, task) do
    prompt = "#{@system_prompt}#{task}"

    payload =
      %{
        "model" => model,
        "temperature" => 0.1,
        "messages" => [
          %{"role" => "user", "content" => prompt}
        ]
      }
      |> Jason.encode!()

    Req.post!(@url, body: payload, headers: headers(), receive_timeout: @timeout).body
    |> Map.get("choices", [%{}])
    |> hd()
    |> get_in(["message", "content"])
  end

  defp headers do
    [
      {"authorization", "Bearer #{openai_api_key()}"},
      {"content-type", "application/json"},
      {"accept", "application/json"}
    ]
  end

  defp openai_api_key, do: System.fetch_env!("LB_OPENAI_API_KEY")
end
```

```elixir
OpenAIClient.call("gpt-4-turbo-preview", "reverse a string for me")
```

## Manage Request to local ollama model

```elixir
defmodule OllamaClient do
  # 5 mins
  @timeout 300_000
  @url "http://localhost:11434/api/generate"
  @system_prompt """
  You are an expert programmer that writes simple, concise code and no comments or explanation.
  Write a elixir module that it reads its input from a file "input.txt" and solve the following task.
  The module should have only one public function called `call` with arity 0.
  TASK:
  """
  def call(model, task) do
    prompt = "#{@system_prompt}#{task}"

    payload =
      Jason.encode!(%{
        "model" => model,
        "prompt" => prompt,
        "stream" => false
      })

    Req.post!(@url, body: payload, receive_timeout: @timeout).body["response"]
  end
end
```

## Code evaluator

```elixir
defmodule EvaluateCode do
  def call(code_string, file_content) do
    try do
      # Step 1: Evaluate the code_string to define the module
      {{:module, module, _, _}, _binding} = Code.eval_string(code_string)

      # Step 2: Save the input file for the evaluation
      File.write!("input.txt", file_content)

      # Step 3: Check if the module and function call/0 exists and then invoke it
      if module && function_exported?(module, :call, 0) do
        result = apply(module, :call, [])
        {:ok, inspect(result)}
      else
        {:error, "No suitable module with a public call/0 function found"}
      end
    rescue
      exception ->
        {:error, Exception.message(exception)}
    end
  end
end
```

## Add mutiple time FunctionRunner

````elixir
defmodule CodeResponseSanitizer do
  def call(input) when is_binary(input) do
    input
    |> String.replace(~r/^(\n|.)*```elixir/, "")
    |> String.replace(~r/```(\n|.)*$/, "")
  end
end

defmodule FunctionRunner do
  def run_max_times(function, max_attempts) do
    do_run_max_times(function, max_attempts, 1)
  end

  defp do_run_max_times(function, max_attempts, attempt) when attempt <= max_attempts do
    case function.() do
      :ok -> :ok
      _ -> do_run_max_times(function, max_attempts, attempt + 1)
    end
  end

  defp do_run_max_times(_function, _max_attempts, _attempt), do: :error
end

task_solver_fn = fn day ->
  task = Map.fetch!(day, "task")
  input = Map.fetch!(day, "input")
  answer = Map.fetch!(day, "answer")

  with module_string <- OpenAIClient.call("gpt-4-turbo-preview", task) |> IO.inspect(label: 1),
       module_sanitized <- CodeResponseSanitizer.call(module_string) |> IO.inspect(label: 2),
       {:ok, result} <- EvaluateCode.call(module_sanitized, input) |> IO.inspect(label: 2),
       true <- String.contains?(result, answer) |> IO.inspect(label: 4) do
    path =
      ~s|#{System.get_env("HOME")}/code/advent_generated/#{day["name"]}.exs|

    File.write!(path, module_sanitized) |> IO.inspect(label: 5)
  else
    error -> error
  end
end
````

````elixir
"Here's the Elixir module that solves the task:\n\n```elixir\ndefmodule Day1 do\n  def call do\n    File.read!(\"input.txt\")\n    |> chars()\n  "
````

```elixir
Enum.map(dataset_2016, fn day ->
  FunctionRunner.run_max_times(fn -> task_solver_fn.(day) end, 3)
end)
```

<!-- livebook:{"offset":6140,"stamp":{"token":"XCP.LugqWEUcBGlzxwkS9tKm5xU6rFXbEZ0ujADfTLqtEdkd_Qoz70GeugbWvQUVe08FQQzaJPqoJLLhGFkSQ1L-vG9T6eb4aMnDqxbRX4V_rwTsPm7YUlvxXWQp8NWurLamUeK5_A3MrNITD3q5gg","version":2}} -->
